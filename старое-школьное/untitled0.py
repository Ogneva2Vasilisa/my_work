# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g2hHwoCKIbsPlgrXriMK9FOg-D2241CX
"""

import numpy as np
import pandas as pd
import csv
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input, Dropout, BatchNormalization, LeakyReLU
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

x,y=[], []
with open('train.csv') as file:
  data = list(csv.reader(file, delimiter =','))[1:]
  i=0
  for row in data:
    try:
      if int(row[1])<90000: row[1]=str((int(data[i-1][1])+int(data[i+1][1]))//2)
    except: row[1]=90306
    i=i+1
  for row in data:
    #день месяц часы
    s=[int(row[0].split()[0][:2]), int(row[0].split()[0][3:5]), int(row[0].split()[0][6:]), int(row[0].split()[1][:2])]
    x.append(s)
    #значение
    y.append(int(row[1]))
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)
print(x)
print(y)

date, score=[], []
for j in range(24):
  x1, y1=[], []
  a=[]
  for i in range(len(data)):
    if i%(24)==j:
      y1.append(int(data[i][1]))
      x1.append(i)
      a.append(x[i])
  #print(a)
  #print(x1)
  #print(y1)
  #print(len(x1))
  plt.figure(figsize=(10, 5))
  plt.plot(x1,y1)
  date.append(a)
  score.append(y1)
print(date)

date

x_prediction=x[:181]

print(x_train)
print(y_train)
Model = LinearRegression()
Model.fit(x_train,y_train)

for i in range(24):
  x_train, x_test, y_train, y_test = train_test_split(date[i], score[i], test_size=0.2)
  Model = LinearRegression()
  Model.fit(x_train,y_train)
  y_test1 = Model.predict(x_test)
  # show the inputs and predicted outputs
  '''for i in range(len(x_test)):
    print(y_test[i],end=' ')
    print("X=%s, Predicted=%s" % (x_test[i], y_test1[i]) )'''
  x_t=[i for i in range(0,len(x_test))]
  plt.figure(figsize=(30, 5))
  plt.plot(x_t, y_test, label='real')
  plt.plot(x_t, y_test1, label='train',color='orange')
  plt.legend()
  plt.show()



from keras.backend import dropout
model = keras.Sequential([
    Dense(16, input_dim=3),
    Dense(16*3, activation='relu'),
    LeakyReLU(),
    Dropout(0.5),
    Dense(16, activation='relu'),
    LeakyReLU(),
    Dense(1,  activation='softmax')

])

model.summary()

model.compile(optimizer='adam', 
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.fit(x, y, epochs = 10, batch_size = 60, shuffle=True)

'''import numpy as np
from sklearn import linear_model
from sklearn import svm
import keras
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input, Dropout, BatchNormalization, LeakyReLU

classifiers = [
    svm.SVR(),
    linear_model.SGDRegressor(),
    linear_model.BayesianRidge(),
    linear_model.LassoLars(),
    linear_model.ARDRegression(),
    linear_model.PassiveAggressiveRegressor(),
    linear_model.TheilSenRegressor(),
    linear_model.LinearRegression()]

trainingData    = np.array([ [2.3, 4.3, 2.5],  [1.3, 5.2, 5.2],  [3.3, 2.9, 0.8],  [3.1, 4.3, 4.0]  ])
trainingScores  = np.array( [3.4, 7.5, 4.5, 1.6] )
predictionData  = np.array([ [2.5, 2.4, 2.7],  [2.7, 3.2, 1.2] ])

for item in classifiers:
    print(item)
    clf = item
    clf.fit(trainingData, trainingScores)
    print(clf.predict(predictionData),'\n')
  '''